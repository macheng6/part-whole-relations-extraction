{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pickle\n",
    "\n",
    "def save(filename, data):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(data, output)\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, 'rb') as output:\n",
    "        data = pickle.load(output)\n",
    "    return data\n",
    "\n",
    "path = 'E:\\Fudan\\part-whole relations\\data_test.txt'\n",
    "filename = 'E:\\Fudan\\part-whole relations\\entities_list.pkl'\n",
    "\n",
    "entities = []\n",
    "with codecs.open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f.readlines():\n",
    "        tmp = ''\n",
    "        cnt = 0\n",
    "        entity = []\n",
    "        for strs in line:\n",
    "            tmp += strs\n",
    "            if strs == '\\t':\n",
    "                cnt += 1\n",
    "                if cnt <= 3:\n",
    "                    tmp = ''\n",
    "                else:\n",
    "                    entity.append(tmp.replace('\\t', ''))\n",
    "                    tmp =''\n",
    "                if cnt >= 6:\n",
    "                    entities.append(entity)\n",
    "                    break\n",
    "\n",
    "\n",
    "entities_ = []\n",
    "for term in entities:\n",
    "    entities_.append(term[0])\n",
    "    entities_.append(term[2])\n",
    "\n",
    "save(filename, entities_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def load(filename):\n",
    "    with open(filename, 'rb') as output:\n",
    "        data = pickle.load(output)\n",
    "    return data\n",
    "\n",
    "filename1 = 'E:\\Fudan\\part-whole relations\\embedding_dict.pkl'\n",
    "filename2 = 'E:\\Fudan\\part-whole relations\\entities_list.pkl'\n",
    "\n",
    "embedding_dict = load(filename1)\n",
    "entities = load(filename2)\n",
    "\n",
    "entities_order = {}\n",
    "offset_list = []\n",
    "cnt = 0\n",
    "for i in range(len(entities)) :\n",
    "    if i % 2 == 0:\n",
    "        entity1 = entities[i]\n",
    "        entity2 = entities[i+1]\n",
    "        entities_order[cnt] = zip(entity1, entity2)\n",
    "        cnt += 1\n",
    "        offset_list.append(embedding_dict[entity1] - embedding_dict[entity2])\n",
    "\n",
    "X = np.array(offset_list)\n",
    "kmeans = KMeans(n_cluster = k).fix(X)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "clusters_cents = kmeans.clusters_centers_\n",
    "\n",
    "clusters_dict = {}   # key是类别i，value是一个属于类别i的元素组成的列表\n",
    "for i in range(len(labels)):\n",
    "    if clusters_dict.get(labels[i]) == None:\n",
    "        clusters_dict[labels[i]] = [i,]\n",
    "    else:\n",
    "        clusters_dict[labels[i]].append(i)\n",
    "\n",
    "\n",
    "selected_list = []\n",
    "for i in range(k):\n",
    "    minDis = float('inf')  # 初始化为最大值\n",
    "    flag = -1\n",
    "    for j in cluster_dict[i]:\n",
    "        # 计算类别i的形心与所属类别i的每个点的欧式距离\n",
    "        distance = np.sqrt(np.sum(np.square(X[j] - clusters_cents[i])))\n",
    "        if minDis > distance:\n",
    "            minDis = distance\n",
    "            flag = j\n",
    "    selected_list.append(entities_order[flag])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': [-0.082752, 0.67204, -0.14987, -0.064983, 0.056491, 0.40228, 0.0027747, -0.3311, -0.30691, 2.0817, 0.031819, 0.013643, 0.30265, 0.0071297, -0.5819, -0.2774, -0.062254, 1.1451, -0.24232, 0.1235, -0.12243, 0.33152, -0.006162, -0.30541, -0.13057, -0.054601, 0.037083, -0.070552, 0.5893, -0.30385, 0.2898, -0.14653, -0.27052, 0.37161, 0.32031, -0.29125, 0.0052483, -0.13212, -0.052736, 0.087349, -0.26668, -0.16897, 0.015162, -0.0083746, -0.14871, 0.23413, -0.20719, -0.091386, 0.40075, -0.17223, 0.18145, 0.37586, -0.28682, 0.37289, -0.16185, 0.18008, 0.3032, -0.13216, 0.18352, 0.095759, 0.094916, 0.008289, 0.11761, 0.34046, 0.03677, -0.29077, 0.058303, -0.027814, 0.082941, 0.1862, -0.031494, 0.27985, -0.074412, -0.13762, -0.21866, 0.18138, 0.040855, -0.113, 0.24107, 0.3657, -0.27525, -0.05684, 0.34872, 0.011884, 0.14517, -0.71395, 0.48497, 0.14807, 0.62287, 0.20599, 0.58379, -0.13438, 0.40207, 0.18311, 0.28021, -0.42349, -0.25626, 0.17715, -0.54095, 0.16596, -0.036058, 0.08499, -0.64989, 0.075549, -0.28831, 0.40626, -0.2802, 0.094062, 0.32406, 0.28437, -0.26341, 0.11553, 0.071918, -0.47215, -0.18366, -0.3]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pickle\n",
    "\n",
    "def save(filename, data):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(data, output)\n",
    "        \n",
    "        \n",
    "path = 'E:\\Fudan\\part-whole relations\\glove.840B.300d.txt'\n",
    "filename = 'E:\\Fudan\\part-whole relations\\embedding_dict.pkl'\n",
    "\n",
    "cnt = 0\n",
    "dicts = {}\n",
    "with codecs.open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    for line in f.readlines():\n",
    "        lists = line.split()\n",
    "        dicts[line[0]] = [float(x) for x in line[1:]]\n",
    "\n",
    "save(filename, dicts)\n",
    "        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
